\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Chapter 1: The reinforcement learning problem}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Self-Play }{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Symmetries}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Greedy Play }{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Learning from Exploration}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}Other improvements}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Multi-armed Bandits}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Longterm epsilon greedy}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Step-size parameters}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Optimistic vs Realistic greedy}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Programming: }{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Epsilon greedy algorithm with $epsilon = 0.1$ on a non-stationary problem.   Blue: stepsize = $\frac  {1}{n}$, Red: stepsie = 0.1\relax }}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Spike in UCB plot}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Epsilon greedy algorithm with $epsilon = 0.1$ on a non-stationary problem.   Blue: stepsize = $\frac  {1}{n}$, Red: stepsie = 0.1\relax }}{7}}
